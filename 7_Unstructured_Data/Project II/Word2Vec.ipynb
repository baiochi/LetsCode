{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e922a1f",
   "metadata": {},
   "source": [
    "<span class='main_title'>NPL with Word2Vec</span>\n",
    "<hr>\n",
    "<span class='author'>author:<a href='github.com/baiochi'>@baiochi<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cac0d9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Notebook Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df39b6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755f85c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:17:27.597944Z",
     "start_time": "2022-05-25T23:17:05.275102Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (4.19.1)\n",
      "Requirement already satisfied: filelock in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: requests in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gensim in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbbe7e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Libraries and APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b707f131",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:17:27.629980Z",
     "start_time": "2022-05-25T23:17:27.611439Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".main_title {\n",
       "    font-family:Lato,sans-serif;\n",
       "    color:#f5b324;\n",
       "    font-size: 3em;\n",
       "}\n",
       "\n",
       "hr {\n",
       "  background: linear-gradient(to right, #00fafd, #f5b324);\n",
       "  height: 2px;\n",
       "}\n",
       "\n",
       "h1 {\n",
       "    font-family:Lato,sans-serif;\n",
       "    color:#f5b324;\n",
       "    font-style: bold;\n",
       "    font-size: 1em;\n",
       "}\n",
       "\n",
       "h2 {\n",
       "    font-family:Lato,sans-serif;\n",
       "    color:#07bbf7;\n",
       "    font-size: 1em;\n",
       "}\n",
       "\n",
       "h3 {\n",
       "    font-family:Lato,sans-serif;\n",
       "    color:#163f41;\n",
       "    font-size: 1em;\n",
       "} \n",
       "\n",
       ".author {\n",
       "    font-family:Lato,sans-serif;\n",
       "    font-style: italic;\n",
       "    font-size: 1em;\n",
       "}\n",
       "\n",
       "table {\n",
       "    margin-left: 0 !important;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Terminal ASCII colors\n",
    "WHITE = '\\033[39m'; CYAN  = '\\033[36m'; ORANGE = '\\033[93m';\n",
    "# Image drawing colors\n",
    "BLUE   = '#00fafd'    # rgb(0,250,253)\n",
    "YELLOW = '#f5b324'    # rgb(245,179,36)\n",
    "# Styling notebook with CSS\n",
    "from IPython.core.display import HTML\n",
    "styles = open(\"./styles/custom.css\", \"r\").read()\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580a2af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:17:34.307371Z",
     "start_time": "2022-05-25T23:17:27.632540Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.4.3\n",
       "numpy               1.20.3\n",
       "pandas              1.3.4\n",
       "session_info        1.0.0\n",
       "sklearn             1.0.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "CoreFoundation              NA\n",
       "Foundation                  NA\n",
       "PIL                         8.4.0\n",
       "PyObjCTools                 NA\n",
       "anyio                       NA\n",
       "appnope                     0.1.2\n",
       "attr                        21.2.0\n",
       "babel                       2.9.1\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "bottleneck                  1.3.2\n",
       "brotli                      NA\n",
       "certifi                     2022.05.18.1\n",
       "cffi                        1.14.6\n",
       "chardet                     4.0.0\n",
       "charset_normalizer          2.0.4\n",
       "cloudpickle                 2.0.0\n",
       "colorama                    0.4.4\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.4.1\n",
       "decorator                   5.1.0\n",
       "defusedxml                  0.7.1\n",
       "entrypoints                 0.3\n",
       "google                      NA\n",
       "idna                        3.2\n",
       "ipykernel                   6.4.1\n",
       "ipython_genutils            0.2.0\n",
       "jedi                        0.18.0\n",
       "jinja2                      2.11.3\n",
       "joblib                      1.1.0\n",
       "json5                       NA\n",
       "jsonschema                  3.2.0\n",
       "jupyter_server              1.4.1\n",
       "jupyterlab_server           2.8.2\n",
       "kiwisolver                  1.3.1\n",
       "markupsafe                  1.1.1\n",
       "matplotlib_inline           NA\n",
       "mkl                         2.4.0\n",
       "mpl_toolkits                NA\n",
       "nbclassic                   NA\n",
       "nbformat                    5.1.3\n",
       "nbinom_ufunc                NA\n",
       "netifaces                   0.11.0\n",
       "numexpr                     2.7.3\n",
       "objc                        8.5b1\n",
       "packaging                   21.0\n",
       "parso                       0.8.2\n",
       "pexpect                     4.8.0\n",
       "pickle5                     NA\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "prometheus_client           NA\n",
       "prompt_toolkit              3.0.20\n",
       "psutil                      5.8.0\n",
       "ptyprocess                  0.7.0\n",
       "pvectorc                    NA\n",
       "pyarrow                     7.0.0\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.4.1\n",
       "pydevd_concurrency_analyser NA\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pyexpat                     NA\n",
       "pygments                    2.10.0\n",
       "pyparsing                   3.0.4\n",
       "pyrsistent                  NA\n",
       "pytz                        2021.3\n",
       "requests                    2.26.0\n",
       "scipy                       1.7.1\n",
       "send2trash                  NA\n",
       "six                         1.16.0\n",
       "sniffio                     1.2.0\n",
       "socks                       1.7.1\n",
       "sphinxcontrib               NA\n",
       "storemagic                  NA\n",
       "threadpoolctl               2.2.0\n",
       "tornado                     6.1\n",
       "traitlets                   5.1.0\n",
       "typing_extensions           NA\n",
       "urllib3                     1.26.7\n",
       "wcwidth                     0.2.5\n",
       "zmq                         22.2.1\n",
       "zope                        NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.29.0\n",
       "jupyter_client      6.1.12\n",
       "jupyter_core        4.8.1\n",
       "jupyterlab          3.2.1\n",
       "notebook            6.4.5\n",
       "-----\n",
       "Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]\n",
       "macOS-10.15.7-x86_64-i386-64bit\n",
       "-----\n",
       "Session information updated at 2022-05-25 20:17\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import session_info\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "session_info.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c933bc31",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23b6c323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:17:34.758072Z",
     "start_time": "2022-05-25T23:17:34.335338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          95000 non-null  int64 \n",
      " 1   tweet_text  95000 non-null  object\n",
      " 2   tweet_date  95000 non-null  object\n",
      " 3   sentiment   95000 non-null  int64 \n",
      " 4   query_used  95000 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load Train Dataset\n",
    "df = pd.read_csv('data/train_dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30df26fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:17:35.278771Z",
     "start_time": "2022-05-25T23:17:34.763497Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tweet_text'] = df['tweet_text'].apply(str.split)\n",
    "\n",
    "# Map labels\n",
    "df['sentiment'] = df['sentiment'].astype('category')\n",
    "labels = df['sentiment'].cat.categories\n",
    "\n",
    "# Prepare data\n",
    "X = df['tweet_text']\n",
    "y = df['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac50f7db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T04:49:07.487393Z",
     "start_time": "2022-05-26T04:49:07.466965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('w2v',\n",
       "                 GensimWord2VecVectorizer(epochs=10, min_count=3, sg=1,\n",
       "                                          vector_size=50)),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=None, booster=None,\n",
       "                               colsample_bylevel=None, colsample_bynode=None,\n",
       "                               colsample_bytree=None, enable_categorical=False,\n",
       "                               gamma=None, gpu_id=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.01,\n",
       "                               max_delta_step=None, max_depth=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=-1, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None,\n",
       "                               reg_alpha=None, reg_lambda=None,\n",
       "                               scale_pos_weight=None, subsample=None,\n",
       "                               tree_method=None, validate_parameters=None,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from data.gensimword2vec import GensimWord2VecVectorizer\n",
    "\n",
    "gensim_word2vec_tr = GensimWord2VecVectorizer(vector_size=50, min_count=3, sg=1, alpha=0.025, epochs=10)\n",
    "\n",
    "xgbc = xgb.XGBClassifier(learning_rate=0.01, n_estimators=100, n_jobs=-1)\n",
    "\n",
    "w2v_xgb = Pipeline([\n",
    "    ('w2v', gensim_word2vec_tr), \n",
    "    ('xgb', xgbc)\n",
    "])\n",
    "w2v_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b7fce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T23:43:22.245042Z",
     "start_time": "2022-05-25T23:24:55.571566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "collecting all words and their counts\n",
      "PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "PROGRESS: at sentence #10000, processed 150438 words, keeping 39675 word types\n",
      "PROGRESS: at sentence #20000, processed 298795 words, keeping 66908 word types\n",
      "PROGRESS: at sentence #30000, processed 447587 words, keeping 90750 word types\n",
      "PROGRESS: at sentence #40000, processed 597464 words, keeping 112795 word types\n",
      "PROGRESS: at sentence #50000, processed 746580 words, keeping 133197 word types\n",
      "PROGRESS: at sentence #60000, processed 897421 words, keeping 152479 word types\n",
      "PROGRESS: at sentence #70000, processed 1047006 words, keeping 171214 word types\n",
      "collected 182129 word types from a corpus of 1137033 raw words and 76000 sentences\n",
      "Creating a fresh vocabulary\n",
      "Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 28275 unique words (15.52% of original 182129, drops 153854)', 'datetime': '2022-05-25T20:24:56.645704', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 965461 word corpus (84.91% of original 1137033, drops 171572)', 'datetime': '2022-05-25T20:24:56.646634', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "deleting the raw counts dictionary of 182129 items\n",
      "sample=0.001 downsamples 36 most-common words\n",
      "Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 785525.9557813054 word corpus (81.4%% of prior 965461)', 'datetime': '2022-05-25T20:24:57.161442', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "estimated required memory for 28275 words and 50 dimensions: 25447500 bytes\n",
      "resetting layer weights\n",
      "Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-05-25T20:24:57.963803', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "Word2Vec lifecycle event {'msg': 'training model with 3 workers on 28275 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-05-25T20:24:57.964818', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'train'}\n",
      "EPOCH 0 - PROGRESS: at 29.99% examples, 232856 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 51.04% examples, 195956 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 73.85% examples, 189357 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 0 - PROGRESS: at 98.38% examples, 189650 words/s, in_qsize 2, out_qsize 1\n",
      "EPOCH 0: training on 1137033 raw words (785743 effective words) took 4.1s, 190583 effective words/s\n",
      "EPOCH 1 - PROGRESS: at 19.24% examples, 143216 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 40.49% examples, 153173 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 67.80% examples, 171314 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 100.00% examples, 191246 words/s, in_qsize 0, out_qsize 1\n",
      "EPOCH 1: training on 1137033 raw words (785772 effective words) took 4.1s, 191209 effective words/s\n",
      "EPOCH 2 - PROGRESS: at 29.08% examples, 215373 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 59.87% examples, 228029 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 87.82% examples, 224063 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 2: training on 1137033 raw words (785711 effective words) took 3.4s, 228736 effective words/s\n",
      "EPOCH 3 - PROGRESS: at 32.62% examples, 248182 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 66.01% examples, 254721 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 100.00% examples, 258004 words/s, in_qsize 0, out_qsize 1\n",
      "EPOCH 3: training on 1137033 raw words (785362 effective words) took 3.0s, 257896 effective words/s\n",
      "EPOCH 4 - PROGRESS: at 29.99% examples, 223264 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 57.17% examples, 216226 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 87.82% examples, 223843 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 4: training on 1137033 raw words (785452 effective words) took 3.4s, 231443 effective words/s\n",
      "EPOCH 5 - PROGRESS: at 29.99% examples, 233339 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 5 - PROGRESS: at 58.97% examples, 229763 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 5 - PROGRESS: at 82.55% examples, 212467 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 5: training on 1137033 raw words (785499 effective words) took 3.8s, 208033 effective words/s\n",
      "EPOCH 6 - PROGRESS: at 24.62% examples, 189827 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 6 - PROGRESS: at 56.29% examples, 214834 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 6 - PROGRESS: at 83.42% examples, 214550 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 6 - PROGRESS: at 94.88% examples, 183510 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 6: training on 1137033 raw words (785791 effective words) took 4.3s, 183106 effective words/s\n",
      "EPOCH 7 - PROGRESS: at 21.89% examples, 161058 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 45.76% examples, 169945 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 55.44% examples, 138924 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 65.15% examples, 120949 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 72.10% examples, 108366 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 79.96% examples, 98274 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 87.82% examples, 90793 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 7: training on 1137033 raw words (785348 effective words) took 8.3s, 94485 effective words/s\n",
      "EPOCH 8 - PROGRESS: at 13.98% examples, 93988 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 24.62% examples, 85681 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 37.89% examples, 87960 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 47.55% examples, 85143 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 54.54% examples, 79184 words/s, in_qsize 4, out_qsize 1\n",
      "EPOCH 8 - PROGRESS: at 66.92% examples, 81448 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 79.96% examples, 83937 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 93.11% examples, 85365 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 8: training on 1137033 raw words (785381 effective words) took 9.1s, 86746 effective words/s\n",
      "EPOCH 9 - PROGRESS: at 13.11% examples, 101808 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 9 - PROGRESS: at 25.49% examples, 92756 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 9 - PROGRESS: at 49.32% examples, 122109 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 9 - PROGRESS: at 58.97% examples, 108691 words/s, in_qsize 5, out_qsize 0\n",
      "EPOCH 9 - PROGRESS: at 81.68% examples, 118697 words/s, in_qsize 6, out_qsize 0\n",
      "EPOCH 9: training on 1137033 raw words (785755 effective words) took 6.1s, 129312 effective words/s\n",
      "Word2Vec lifecycle event {'msg': 'training on 11370330 raw words (7855814 effective words) took 49.8s, 157819 effective words/s', 'datetime': '2022-05-25T20:25:47.742381', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'train'}\n",
      "Word2Vec lifecycle event {'params': 'Word2Vec<vocab=28275, vector_size=50, alpha=0.025>', 'datetime': '2022-05-25T20:25:47.743468', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.15.7-x86_64-i386-64bit', 'event': 'created'}\n",
      "/Users/baiochi/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:36:21] WARNING: /private/var/folders/_m/3m0bcc4n6h73gny0bt6_g4x80000gn/T/pip-install-4m5tp6_t/xgboost_17c0d7c1e7cb4a3aab80bf74764ec6a2/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('w2v',\n",
       "                 GensimWord2VecVectorizer(epochs=10, min_count=3, sg=1,\n",
       "                                          vector_size=50)),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.01,\n",
       "                               max_delta_step=0, max_depth=6,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=-1, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52ebe1b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:01:06.351444Z",
     "start_time": "2022-05-26T00:48:28.072074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy 0.8994868421052632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[22298,  2728,   267],\n",
       "       [ 2411, 22057,   891],\n",
       "       [  197,  1145, 24006]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "y_train_pred = w2v_xgb.predict(X_train)\n",
    "print('Training set accuracy %s' % accuracy_score(y_train, y_train_pred))\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "923850d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:03:06.903493Z",
     "start_time": "2022-05-26T01:01:06.365005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy 0.8861578947368421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5520,  809,   74],\n",
       "       [ 650, 5410,  259],\n",
       "       [  55,  316, 5907]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = w2v_xgb.predict(X_test)\n",
    "print('Test set accuracy %s' % accuracy_score(y_test, y_test_pred))\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b55d9f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T04:46:20.932129Z",
     "start_time": "2022-05-26T04:46:20.919479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 28275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('frita', 0.9662717580795288),\n",
       " ('brigadeiro', 0.9132557511329651),\n",
       " ('academia,', 0.9101062417030334),\n",
       " ('conchinha', 0.9022582769393921),\n",
       " ('cvs', 0.9019947052001953),\n",
       " ('morango', 0.9016848206520081),\n",
       " ('strogonoff', 0.9012042880058289),\n",
       " ('cÃ³lica,', 0.8967577815055847),\n",
       " ('tres', 0.895926296710968),\n",
       " ('bola,', 0.8922023773193359)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(w2v_xgb.named_steps['w2v'].model_.wv.index_to_key)\n",
    "print('vocabulary size:', vocab_size)\n",
    "w2v_xgb.named_steps['w2v'].model_.wv.most_similar(positive=['batata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920e131f",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8339e550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T05:07:42.302341Z",
     "start_time": "2022-05-26T05:07:41.969143Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "# Load Train Dataset\n",
    "df = pd.read_csv('data/train_dataset.csv')\n",
    "X = df['tweet_text']\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1219d988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T05:12:45.292988Z",
     "start_time": "2022-05-26T05:12:34.776254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(alpha=10, base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=0.3, enable_categorical=False,\n",
       "                               eval_metric='logloss', gamma=0, gpu_id=-1,\n",
       "                               importance_type=None, interaction_constraints='',\n",
       "                               learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=10,\n",
       "                               n_jobs=-1, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=0, reg_alpha=10, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', use_label_encoder=False, ...))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('xgb', XGBClassifier( \n",
    "        learning_rate = 0.1,\n",
    "        max_depth = 5, \n",
    "        alpha = 10,\n",
    "        colsample_bytree = 0.3,\n",
    "        n_estimators = 10,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False, \n",
    "        n_jobs=-1,) ),\n",
    "])\n",
    "\n",
    "# X is the dataframe we created in previous snippet\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b04f80d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T05:15:30.046960Z",
     "start_time": "2022-05-26T05:15:29.955870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:15:29] WARNING: /private/var/folders/_m/3m0bcc4n6h73gny0bt6_g4x80000gn/T/pip-install-4m5tp6_t/xgboost_17c0d7c1e7cb4a3aab80bf74764ec6a2/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = X.astype('category')\n",
    "# X is a dataframe we created in previous snippet\n",
    "Xy = xgb.DMatrix(X, y, enable_categorical=True)\n",
    "booster = xgb.train({\"tree_method\": \"hist\", \"max_cat_to_onehot\": 5}, Xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "58d82ab0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T05:15:56.922533Z",
     "start_time": "2022-05-26T05:15:46.320636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "SHAP = booster.predict(Xy, pred_interactions=True)\n",
    "\n",
    "# categorical features are listed as \"c\"\n",
    "print(booster.feature_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04b66b5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T05:13:33.655559Z",
     "start_time": "2022-05-26T05:13:33.245367Z"
    }
   },
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, capture_output, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_input_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mpopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_m/3m0bcc4n6h73gny0bt6_g4x80000gn/T/ipykernel_27748/1584618165.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Or get a matplotlib axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get feature importances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/plotting.py\u001b[0m in \u001b[0;36mplot_tree\u001b[0;34m(booster, fmap, num_trees, rankdir, ax, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;34m'<?xml version='\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m         return self._pipe_legacy(format,\n\u001b[0m\u001b[1;32m    100\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphviz/_tools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                               category=category)\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_legacy\u001b[0;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    112\u001b[0m                      \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                      encoding: typing.Optional[str] = None) -> typing.Union[bytes, str]:\n\u001b[0;32m--> 114\u001b[0;31m         return self._pipe_future(format,\n\u001b[0m\u001b[1;32m    115\u001b[0m                                  \u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                                  \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphviz/piping.py\u001b[0m in \u001b[0;36m_pipe_future\u001b[0;34m(self, format, renderer, formatter, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pipe_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphviz/backend/piping.py\u001b[0m in \u001b[0;36mpipe_lines\u001b[0;34m(engine, format, input_lines, input_encoding, renderer, formatter, quiet)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_lines'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_encoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphviz/backend/execute.py\u001b[0m in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, capture_output, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a graph\n",
    "graph = xgb.to_graphviz(clf.named_steps['xgb'], num_trees=1)\n",
    "# Or get a matplotlib axis\n",
    "ax = xgb.plot_tree(clf.named_steps['xgb'], num_trees=1)\n",
    "# Get feature importances\n",
    "clf.named_steps['xgb'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f9b4b71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T04:51:38.796789Z",
     "start_time": "2022-05-26T04:51:38.791947Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:linear\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942babc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e3a8069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T04:49:18.092148Z",
     "start_time": "2022-05-26T04:49:18.071506Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tree must be Booster, XGBModel or dict instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_m/3m0bcc4n6h73gny0bt6_g4x80000gn/T/ipykernel_27748/1584083881.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/xgboost/plotting.py\u001b[0m in \u001b[0;36mplot_importance\u001b[0;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, fmap, importance_type, max_num_features, grid, show_values, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tree must be Booster, XGBModel or dict instance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimportance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tree must be Booster, XGBModel or dict instance"
     ]
    }
   ],
   "source": [
    "xgb.plot_importance(w2v_xgb)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca428b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11729fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c176f981",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa246b3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T01:03:06.998912Z",
     "start_time": "2022-05-26T01:03:06.998891Z"
    }
   },
   "outputs": [],
   "source": [
    "# the keras model/graph would look something like this:\n",
    "from keras import layers, optimizers, Model\n",
    "\n",
    "# adjustable parameter that control the dimension of the word vectors\n",
    "embed_size = 100\n",
    "\n",
    "input_center = layers.Input((1,))\n",
    "input_context = layers.Input((1,))\n",
    "\n",
    "embedding = layers.Embedding(vocab_size, embed_size, input_length=1, name='embed_in')\n",
    "center = embedding(input_center)  # shape [seq_len, # features (1), embed_size]\n",
    "context = embedding(input_context)\n",
    "\n",
    "center = layers.Reshape((embed_size,))(center)\n",
    "context = layers.Reshape((embed_size,))(context)\n",
    "\n",
    "dot_product = layers.dot([center, context], axes=1)\n",
    "output = layers.Dense(1, activation='sigmoid')(dot_product)\n",
    "model = Model(inputs=[input_center, input_context], outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=0.01))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80db16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e4247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
