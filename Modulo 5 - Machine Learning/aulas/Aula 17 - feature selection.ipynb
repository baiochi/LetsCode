{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 17 - feature selection\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Lasso\n",
    "- 3) Feature importance com árvores\n",
    "- 4) RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T23:34:29.963466Z",
     "start_time": "2022-03-09T23:34:29.950472Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T23:34:30.430022Z",
     "start_time": "2022-03-09T23:34:30.410031Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "def metricas_classificacao(estimator, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # ============================================\n",
    "\n",
    "    print(\"\\nMétricas de avaliação de treino:\")\n",
    "\n",
    "    y_pred_train = estimator.predict(X_train)\n",
    "\n",
    "    print(confusion_matrix(y_train, y_pred_train))\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(y_train, y_pred_train)\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "    # ============================================\n",
    "\n",
    "    print(\"\\nMétricas de avaliação de teste:\")\n",
    "\n",
    "    y_pred_test = estimator.predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(y_test, y_pred_test)\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introdução\n",
    "\n",
    "O processo de **feature selection** (**seleção de atributos**) consiste na escolha, com base em alguns critérios, de um **subconjunto do conjunto original** de features de um dado problema, que proporcionem um modelo com performance comparável ao modelo treinado com todas as features. \n",
    "\n",
    "<img src=https://miro.medium.com/max/694/0*D_jQ5yBsvCZjEYIW width=400>\n",
    "\n",
    "O resultado do processo de feature selection é uma **redução na dimensionalidade** do espaço de features do problema (mas aqui, diferente do PCA, trabalhamos no espaço de features originais!)\n",
    "\n",
    "Assim, o processo remove features redundantes ou irrelevantes. \n",
    "\n",
    "Dentre as vantagens do procedimento, podemos destacar:\n",
    "\n",
    "- Maior eficiência no treinamento (afinal, reduzimos a quantidade de informação a ser processada);\n",
    "- Eliminação de redundâncias (como multicolinearidade, por exemplo, que pode ser problemática para alguns estimadores);\n",
    "- Um modelo mais enxuto, com menos features, é, em geral, mais facilmente interpretável;\n",
    "- Ao reduzirmos o número de features, a complexidade da hipótese é reduzida, o que pode favorecer a generalização;\n",
    "\n",
    "O princípio da [navalha de Occam](https://pt.wikipedia.org/wiki/Navalha_de_Ockham) é relevante no contexto de feature selection em projetos de machine learning. Sugiro [este post](https://machinelearningmastery.com/ensemble-learning-and-occams-razor/#:~:text=Occam's%20razor%20suggests%20that%20in,narrow%20and%20not%20generalize%20well.) para uma discussão deste princípio como uma heurística para a construção de modelos. Para uma discussão mais profunda, sugiro [este paper](https://www.aaai.org/Papers/KDD/1998/KDD98-006.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na aula de hoje, veremos alguns procedimentos de feature selection. Vamos começar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) LASSO\n",
    "\n",
    "Já conhecemos um método capaz de realizar feature selection: a **regularização L1 (LASSO)**.\n",
    "\n",
    "Diferente da regularização L2, quando utilizamos regularização L1 é possível zerar alguns dos parâmetros do modelo:\n",
    "\n",
    "<img src=https://ugc.futurelearn.com/uploads/assets/2b/fe/2bfe399e-503e-4eae-9138-a3d7da738713.png width=800>\n",
    "\n",
    "Embora ambas as modalidades de regularização tenha, sido introduzidas com o intuito de simplificar o espaço de hipóteses, o LASSO faz isso de maneira explítica, efetivamente possibilitando a realização de feature selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, há um problema: são poucos os métodos que têm o LASSO incorporado (ex.: regressão linear, logística, XGBoost).\n",
    "\n",
    "Assim, se quisermos realizar feature selection utilizando outros estimadores, precisamos de técnicas mais genéricas, que é o que veremos a seguir.\n",
    "\n",
    "Para utilizarmos o L1, uma abordagem possível é:\n",
    "\n",
    "- **treinar inicialmente um modelo com LASSO**; \n",
    "- identificar quais features **ainda estão presentes no modelo** (isto é, com `coef_` não nulo);\n",
    "- utilizar estas features apenas para treinar o estimador desejado.\n",
    "\n",
    "Embora esta seja uma possibilidade, veremos, a seguir, que há técnicas que possibilitam este procedimento, de maneira mais geral!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature importance com árvores\n",
    "\n",
    "Além de estimadores poderosos, podemos utilizar árvores para fazer feature selection! \n",
    "\n",
    "Há duas formas comuns de utilizarmos árvores para a determinação da importância de features. Vamos conhecer cada uma na prática, utilizando um dataset familiar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T23:34:34.387763Z",
     "start_time": "2022-03-09T23:34:34.298809Z"
    }
   },
   "outputs": [],
   "source": [
    "df_bc = pd.read_csv(\"../datasets/breast_cancer.csv\")\n",
    "\n",
    "X = df_bc.drop(columns=[\"id\", \"diagnosis\"])\n",
    "y = df_bc[\"diagnosis\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.feature_importances_`, com base em decréscimo de impureza (MDI)\n",
    "\n",
    "Neste caso, o score de importância de cada uma das features é calculado com base na **média e desvio padrão da diminuição de impureza que cada feature proporciona na árvore (ou em cada árvore, no caso de ensembles)**.\n",
    "\n",
    "O método é conhecido como **mean decrease in impurity** (MDI).\n",
    "\n",
    "Este método é rápido, no entanto, o valor é fortemente enviesado para features que têm alta cardinalidade (features numéricas, ou features categóricas com muitos níveis).\n",
    "\n",
    "Neste caso, é melhor utilizar o método de permutation feature importance. Para uma comparação detalhada entre os dois métodos, [veja esta página](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados não são tão legais com uma única árvore. O método fica mais robusto se utilizarmos um ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada na variação..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variação é enorme! O que pode ter acontecido?\n",
    "\n",
    "Isso se deve justamente ao viés indesejado que é introduzido pelo MDI. Para corrigir isso, vamos introduzir um novo método!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `permutation_importance()`, com base em permutação de features\n",
    "\n",
    "Neste método, utilizamos a função `sklearn.inspection.permutation_importance()`, que vai criar permutações das features, mantendo um registro de um score, e como ele é afetado quando uma ou outra feature é eliminada.\n",
    "\n",
    "Por realizar diversas permutações, este método é mais custoso, mas tem a vantagem de eliminar o viés que features de alta cardinalidade carregam com o método baseado em impureza.\n",
    "\n",
    "Para maiores detalhes sobre o método, [clique aqui!](https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-importance)\n",
    "\n",
    "> Observação: embora tenhamos ilustrado a importância de permutação com a árvore de decisão, na realidade este é um método que pode ser usado com qualquer estimador!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função que vamos utilizar [está aqui!](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) RFE\n",
    "\n",
    "Conheceremos agora o método **Recursive Feature Elimination** (RFE).\n",
    "\n",
    "O RFE é um método que se utiliza de um estimador capaz de atribuir um score de **importância** a cada uma das features.\n",
    "\n",
    "> Por exemplo, podemos olhar para os coeficientes de um modelo linear (`coef_`), ou então, para os scores de importância de features (`feature_importances_`).\n",
    "\n",
    "O método então considera recursivamente **subconjuntos cada vez menores de features**, da seguinte maneira:\n",
    "\n",
    "- O estimador é treinado inicialmente com todas as features;\n",
    "- A importância de cada uma das features é calculada;\n",
    "- As features menos importantes são retiradas do conjunto de features;\n",
    "- O processo recomeça, até que o número  desejado de features seja alcançado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sendo assim, temos dois hiperparâmetros importantes na classe [RFE](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html):\n",
    "\n",
    "- `estimator`: o estimador que irá disponibilizar os scores de importância de features;\n",
    "- `n_features_to_select`: a quantidade de features que o subconjunto final terá.\n",
    "\n",
    "Na prática, podemos utilizar um gridsearch para otimizar estes dois hiperparâmetros, ou então utilizar a classe [RFECV](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html), que determina o melhor númeo de features automaticamente.\n",
    "\n",
    "Vamos ver o método na prática!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver como funciona o [RFECV](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, podemos incluir o RFE como um passo da Pipeline, e otimizar seus parâmetros com o grid search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T07:17:28.662190Z",
     "start_time": "2022-03-09T07:17:28.630445Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T07:36:31.306412Z",
     "start_time": "2022-03-09T07:35:45.251839Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RFE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9868/4190285313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m pipe = Pipeline([(\"rfe\", RFE(estimator=DecisionTreeClassifier(random_state=42))),\n\u001b[0m\u001b[0;32m      4\u001b[0m                  (\"ab\", AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,\n\u001b[0;32m      5\u001b[0m                                                                                  \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gini\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RFE' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "pipe = Pipeline([(\"rfe\", RFE(estimator=DecisionTreeClassifier(random_state=42))),\n",
    "                 (\"ab\", AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,\n",
    "                                                                                 criterion=\"gini\",\n",
    "                                                                                 max_features=\"sqrt\",\n",
    "                                                                                 random_state=42),\n",
    "                                           random_state=42))])\n",
    "\n",
    "param_grid_ab = {\"rfe__n_features_to_select\" : range(1, X_train.shape[1]+1),\n",
    "                 \"ab__n_estimators\" : [100, 150]}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_ab = GridSearchCV(pipe, param_grid_ab, scoring=\"f1_weighted\", cv=splitter, verbose=10, n_jobs=-1)\n",
    "\n",
    "grid_ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T07:36:31.337409Z",
     "start_time": "2022-03-09T07:36:31.309424Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_ab.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T07:36:31.906817Z",
     "start_time": "2022-03-09T07:36:31.340406Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metricas_classificacao(grid_ab, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos mudar o estimador do RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T07:46:34.785351Z",
     "start_time": "2022-03-09T07:45:43.279542Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline([(\"ss\", StandardScaler()),\n",
    "                 (\"rfe\", RFE(estimator=LogisticRegression(random_state=42,\n",
    "                                                          penalty=\"l1\",\n",
    "                                                          solver=\"liblinear\"))),\n",
    "                 (\"ab\", AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,\n",
    "                                                                                 criterion=\"gini\",\n",
    "                                                                                 max_features=\"sqrt\",\n",
    "                                                                                 random_state=42),\n",
    "                                           n_estimators=150,\n",
    "                                           random_state=42))])\n",
    "\n",
    "param_grid_ab = {\"rfe__estimator__C\" : [0.001, 0.01],\n",
    "                 \"rfe__n_features_to_select\" : range(1, X_train.shape[1]+1)}\n",
    "\n",
    "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_ab = GridSearchCV(pipe, param_grid_ab, scoring=\"f1_weighted\", cv=splitter, verbose=10, n_jobs=-1)\n",
    "\n",
    "grid_ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T07:46:34.800629Z",
     "start_time": "2022-03-09T07:46:34.785351Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_ab.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-09T07:46:35.458705Z",
     "start_time": "2022-03-09T07:46:34.804626Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metricas_classificacao(grid_ab, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
