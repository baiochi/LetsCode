{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 4 - Regressão Logística\n",
    "\n",
    "Na aula de hoje, vamos explorar os seguintes tópicos em Python:\n",
    "\n",
    "- 1) Introdução\n",
    "- 2) Regressão logística\n",
    "- 4) Métricas de performance para problemas de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Introdução\n",
    "\n",
    "**Problemas de classificação** são aqueles em que queremos determinar a que **categoria ou classe** dentro de um **conjunto discreto de classes** uma dada observação pertence, com base em suas features.\n",
    "\n",
    "Para isso, construímos um **classificador**: modelo que tem como input as features (contínuas ou discretas) e como output uma entre as classes (discretas).\n",
    "\n",
    "> Principal diferença entre problemas de regressão e classificação:\n",
    "> - Regressão: valores contínuos;\n",
    "> - Classificação: valores (classes) discretas (binárias ou não).\n",
    "\n",
    "<img src=\"https://i0.wp.com/vinodsblog.com/wp-content/uploads/2018/11/Classification-vs-Regression.png?fit=2048%2C1158&ssl=1\" width=700>\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/71/8e/6a/718e6a40e1782bead960e58d3c52663b.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemas de classificação são comumente divididos com relação ao **número de classes** a serem preditas (isto é, com relação à estrutura do espaço de target):\n",
    "\n",
    "- Classificação binária: duas classes (0 e 1);\n",
    "- Classificação multiclasse: $n$ classes (0, 1, ..., $n-1$), com $n > 2 \\in \\mathbb{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplos de problemas de classificação:\n",
    "- Detecção de e-mails SPAM: um e-mail é SPAM ou não?;\n",
    "    - Features: palavras contidas no corpo do e-mail; remetente; assunto;\n",
    "- Detecção de doenças: que codição médica a pessoa tem?\n",
    "    - Features: sintomas fisiológicos; resultados de exames (medidas de variáveis biológicas);\n",
    "- Detecção do tipo de documento: secreto, confidencial ou não-sensível?\n",
    "    - Features: palavras no corpo do texto; título;\n",
    "- Detecção de fraudes de cartão de crédito: uma operação é fraudulenta ou não?;\n",
    "    - Features: histórico de transações; hora, local e frequência das transações; tipo de compra;\n",
    "- Modelo de risco de crédito: qual é a chance de determinada pessoa não pagar seu empréstimo?\n",
    "    - Features: histórico de pagamento; score de crédito;\n",
    "    \n",
    "    \n",
    "<img src=\"https://developers.google.com/machine-learning/guides/text-classification/images/TextClassificationExample.png\" width=500>\n",
    "\n",
    "\n",
    "\n",
    "Veremos hoje um dos mais simples e importantes classificadores: a **Regressão Logística!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Regressão Logística\n",
    "\n",
    "A [Regressão Logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) (também chamado de **logit**), apesar do nome, é um método que aplicaremos a problemas de classificação!\n",
    "\n",
    "O objetivo da regressão logística é: **modelar a probabilidade $P(\\vec{x})$ de dada observação (com features $\\vec{x}$) pertencer à classe 1**, ou seja, queremos modelar:\n",
    "\n",
    "$$ P( y = 1 | \\vec{x}) $$\n",
    "\n",
    "Naturalmente, $0 \\le P(\\vec{x}) \\le 1$. \n",
    "\n",
    "Uma vez que tivermos uma função que modele a probabilidade acima, podemos tomar a decisão de classificação da seguinte maneira:\n",
    "\n",
    "- $P(\\vec{x}) \\ge 0,5$: x pertence à classe 1\n",
    "- $P(\\vec{x}) < 0.5$: x pertence à classe 0\n",
    "\n",
    "Obs.: este valor de 0.5 (50%) é chamado de \"cutoff\", e pode ser ajustado, embora seja comum fixá-lo em 50%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderíamos pensar em utilizar a regressão linear em nossos problemas de classificação, mas isso não é uma boa ideia: acabamos encontrando probabilidades negativas e fit ruim!\n",
    "\n",
    "No exemplo a seguir, temos a probabilidade de não-pagamento (default) de um empréstimo com base em uma feature (balanço). Note probabilidades negativas!\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/70189f79-2886-4e59-893b-1dac9dd64078.png\" height=\"400\" width=\"400\">\n",
    "</figure> \n",
    "\n",
    "Para resolver este problema, podemos adaptar a função de regressão linear para uma função que tem imagem entre 0 e 1. Seria legal se tivéssemos algo como:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/6d54529a-d295-47a3-8a11-1f426fde7229.png\" height=\"400\" width=\"400\">\n",
    "</figure> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um exemplo de tal função é a **função logística** ou **função sigmoidal**:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/970/1*Xu7B5y9gp0iL5ooBj7LtWw.png\" width=400>\n",
    "\n",
    "Note que:\n",
    "\n",
    "- $z \\in \\mathbb{R}$\n",
    "- $0 \\le \\phi(z) \\le 1$\n",
    "\n",
    "Para incorporar a ideia da regressão linear na regressão logística, tomamos:\n",
    "\n",
    "- $z = b_0 + b_1x$, que é o modelo de regressão linear (uma variável);\n",
    "\n",
    "E substituímos na função logística:\n",
    "\n",
    "- $\\phi(x) = \\frac{1}{1 + e^{-(b_0 + b_1 x)}}$\n",
    "\n",
    "Com isso, tomamos qualquer output real do modelo linear e transformamos em um valor entre 0 e 1, como queríamos!\n",
    "\n",
    "<img src=\"https://s3-sa-east-1.amazonaws.com/lcpi/e5ecf372-6790-49db-9bad-95bc4b19df27.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nosso caso, como queremos modelar probabilidades, a função acima é exatamente a **hipótese** do estimador de regressão logística! Isto é,\n",
    "\n",
    "$$f_{H, \\vec{b}}(x) = P(x) = \\frac{1}{1 + e^{-(b_0 + b_1 x)}}$$\n",
    "\n",
    "Ou, para a regressão logística múltipla com $p$ features $\\vec{x} = x_1, \\cdots, x_p$:\n",
    "\n",
    "$$f_{H, \\vec{b}}(\\vec{x}) = P(\\vec{x}) = \\frac{1}{1 + e^{-(b_0 + b_1 x_1 + \\cdots + b_p x_p)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com um pouco de álgebra, é possível mostrar que: \n",
    "\n",
    "$ b_0 + b_1 x_1 + \\cdots + b_p x_p = \\log \\left ( \\frac{P}{1-P} \\right ) $\n",
    "\n",
    "A quantidade $\\frac{P}{1-P}$ é conhecida como **odds/chance**; e $\\log \\left ( \\frac{P}{1-P} \\right )$ é o [log-odds ou logit](https://en.wikipedia.org/wiki/Logit).\n",
    "\n",
    "Note, portanto, que podemos entender a regressão logística como um modelo em que **o logit é linear com as features**. Portanto, de fato, a regressão logística é **um modelo linear**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na regressão logística, nosso conjunto de hipóteses é: $\\mathcal{H} = \\left \\{ \\frac{1}{1 + e^{-(b_0 + b_1 x_1 + \\cdots + b_p x_p)}} \\right \\}$.\n",
    "\n",
    "O objetivo do algoritmo de aprendizagem será, como sempre, determinar qual é o vetor de parâmetros $\\vec{b}$ que produz uma função $ $ que **melhor se ajusta aos dados**.\n",
    "\n",
    "Para ilustrar este ponto novamente, vamos produzir a seguir algumas das infinitas funções de $\\mathcal{H}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "### Função de perda e algoritmo de aprendizagem\n",
    "\n",
    "A função de perda para a regressão logística é a famosa [binary cross-entropy](https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a), também conhecida como [log loss](https://developers.google.com/machine-learning/crash-course/logistic-regression/model-training)\n",
    "\n",
    "Esta função será de enorme importância no estudo de **redes neurais**.\n",
    "\n",
    "As principais implementações do algoritmo de aprendizagem da regressão logística se baseia no [método de máxima verossimilhança](https://pt.wikipedia.org/wiki/M%C3%A1xima_verossimilhan%C3%A7a). \n",
    "\n",
    "Para maiores detalhes sobre o algoritmo de aprendizagem, veja [este vídeo](https://youtu.be/yIYKR4sgzI8) e [esta série de vídeos](https://youtu.be/vN5cNN2-HWE), do ótimo canal StatQuest!\n",
    "\n",
    "\n",
    "_________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "\n",
    "Para introduzirmos as ideias, utilizaremos um dataset de marketing (propagandas/advertising), que está disponível no <a href=\"https://www.kaggle.com/fayomi/advertising\">Kaggle</a>. Este é um dataset artificial e didático, com os dados bem separáveis, o que é ótimo para ilustração!<br>\n",
    "\n",
    "Visite o Kaggle e procure por \"advertising\" para datasets relacionados reais e ainda mais interessantes\n",
    "\n",
    "A base que utilizaremos contém as seguintes colunas:\n",
    "\n",
    "* 'Daily Time Spent on Site': tempo que o cliente ficou no site (em minutos);\n",
    "* 'Age': idade do cliente (em anos);\n",
    "* 'Area Income': média salarial (por ano) da região geográfica do cliente;\n",
    "* 'Daily Internet Usage': tempo médio (em minutos) que o cliente fica na internet;\n",
    "* 'Ad Topic Line': título do anúncio;\n",
    "* 'City': cidade do cliente;\n",
    "* 'Male': dummy indicando se o cliente é do sexo masculino (1) ou não (0);\n",
    "* 'Country': país do cliente;\n",
    "* 'Timestamp': marcação de tempo em que o cliente clickou no anúncio OU fechou a página\n",
    "* 'Clicked on Ad': dummy indicando se o cliente clickou no anúncio (1) ou não (0).\n",
    "\n",
    "Nosso objetivo é criar um modelo que possa prever se um determinado usuário clickará em um anúncio online ou não, com base em suas características pessoais/comportamentais, bem como informações relativas ao anúncio.\n",
    "\n",
    "Tomamos como variáveis independentes (preditores/features) as primeiras 9 colunas, enquanto nossa variável dependente (target) é a última coluna (\"Clicked on Ad\").\n",
    "\n",
    "Ou seja, nosso modelo deve ser capaz de dizer se um usuário com um conjunto particular das 9 features clickará no anúncio ou não. \n",
    "\n",
    "__IMPORTANTE!__\n",
    "\n",
    "Pense no problema de negócio que estamos querendo resolver com nosso modelo -- direcionamento de marketing! Temos os dados dos nossos clientes (customer-centric), nós os conhecemos! Não podemos utilizar essa informação a nosso favor?\n",
    "\n",
    "Talvez não faça sentido exibir o anúncio para um usuário que tem baixa probabilidade de clickar no ad, não é mesmo? \n",
    "\n",
    "Por outro lado, é muito mais eficiente direcionar nosso marketing aos clientes com alta chance de clickar no nosso anúncio!\n",
    "\n",
    "Assim, economizamos dinheiro (todo anúncio é pago!), e ganhamos em eficiência e alcance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo é apenas para formatar os números em até 3 casas decimais. \n",
    "\n",
    "Fica aqui pra conhecimento e também pq vai nos auxiliar a ver melhor as probabilidades no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T01:37:58.731197Z",
     "start_time": "2020-02-14T01:37:58.711810Z"
    }
   },
   "source": [
    "Alguma observação notável?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos um dataset balanceado no target, o que __bem raro na vida real!__\n",
    "\n",
    "Um dataset desbalanceado pode causar sérios problemas de performance ao modelo! Há várias técnicas para lidar com tal problema, mas, neste primeiro exemplo, não nos preocuparemos com isso..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tínhamos comentado no início, nossos dados são muito bem separáveis!\n",
    "\n",
    "Isto favorece bastante a performance do nosso modelo. Mas, lembre-se, é bem raro encontrar casos assim na vida real! (É aí que devemos partir para métodos mais avançados, como SVM, árvores, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos começar a construir o modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Modelo treinado!__\n",
    "\n",
    "Vamos ver os coeficientes do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se que, diferentemente da regressão linear, devido ao fato da função logística ser uma exponencial, a variação de $P(x)$ depende de x, e não apenas dos coeficientes! Então, a interpretação dos coeficientes não é tão imediata. \n",
    "\n",
    "Mas, os sinais carregam significado. Para um coeficiente:\n",
    "- positivo ($b_i > 0$), temos que um aumento em x levará a um aumento de $P(x)$;\n",
    "- negativo ($b_i < 0$), temos que um aumento em x levará a uma diminuição de $P(x)$\n",
    "\n",
    "Mas, a variacão de $P(x)$ em si, depende do valor de x!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Agora que o modelo está treinado, vamos avaliá-lo!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "_____\n",
    "_____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Métricas de performance para problemas de classificação\n",
    "\n",
    "Após treinar o modelo, como podemos avaliar sua performance?\n",
    "\n",
    "No caso de problemas de classificação, existem **métricas específicas**, e também um importante conceito chamado de **Matriz de Confusão**.\n",
    "\n",
    "A **matriz de confusão** leva em consideração as **classes preditas** e as **classes verdadeiras** da base de **teste**, e contabiliza a performance do modelo:\n",
    "\n",
    "<img src=https://diegonogare.net/wp-content/uploads/2020/04/matrizConfusao-600x381.png height=\"400\" width=\"400\">\n",
    "\n",
    "No Sklearn, a notação muda um pouco:\n",
    "\n",
    "<img src=\"https://static.packt-cdn.com/products/9781838555078/graphics/C13314_06_05.jpg\" width=400>\n",
    "\n",
    "Note que a diagonal principal são as observações que o modelo acertou! Temos:\n",
    "\n",
    "- Verdadeiros Positivos (VP): classificação correta da classe positivo;\n",
    "- Verdadeiros Negativos (VN): classificação correta da classe negativo;\n",
    "- Falsos Positivos (FP, erro tipo I): correto: negativo. Previsto: positivo.\n",
    "- Falsos Negativos (FN, erro tipo II): correto: positivo. Previsto: negativo.\n",
    "\n",
    "Um jeito fácil de lembrar os tipos de erros:\n",
    "\n",
    "\n",
    "<img src=\"https://i.pinimg.com/originals/f6/9b/11/f69b111014ef466fe541a393346d2c3a.jpg\" height=\"400\" width=\"400\">\n",
    "\n",
    "\n",
    "Além disso, temos as seguintes métricas numéricas de avaliação:\n",
    "\n",
    "- Acurácia (Accuracy): porcentagem de classificações CORRETAS do modelo;\n",
    "\n",
    "- Precisão (Precision): das respostas retornadas, quantas são relevantes? -- é a razão entre verdadeiros positivos e o  número de **preditos positivos**, isto é, positivos quanto à **label predita pelo modelo**.\n",
    "\n",
    "- Revocação/Sensibilidade (Recall/Sensitivity): das respostas relevantes, quantas são retornadas? -- é a razão entre verdadeiros positivos e o  número de **verdadeiramente positivos**, isto é, positivos quanto à **label real**.\n",
    "\n",
    "- F1-Score: média harmônica de precision e recall.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/1200px-Precisionrecall.svg.png\" width=300>\n",
    "\n",
    "Devido ao <a href=\"https://medium.com/opex-analytics/why-you-need-to-understand-the-trade-off-between-precision-and-recall-525a33919942\">tradeoff entre precision e recall</a>, uma métrica que em muitos casos é interessante de ser otimizada é o F1! \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1080/1*t1vf-ofJrJqtmam0KSn3EQ.png\" height=\"400\" width=\"400\">\n",
    "\n",
    "Adiante, veremos como calcular a matriz de confusão e as métricas acima para problemas de classificação!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ponto muito importante é que o método `predict()` se utiliza do cutoff igual a 0.5 para tomar a decisão! Veremos mais detalhes sobre isso mais a frente. Por enquanto, vamos seguir com a avaliação do modelo com este cutoff padrão!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos no passo 2, em problemas de classificação é muito comum utilizarmos a **matriz de confusão** e as **métricas de classificação** para avaliar nossos modelos.\n",
    "\n",
    "Dado isso, o sklearn já disponibilica estas funcionalidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme esperado, nosso modelo está muito bom! Um f1-score tão alto na vida real é algo notável!\n",
    "\n",
    "Isso se deve à grande separabilidade dos nossos dados!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além dos coeficientes do modelo, algo muito interessante que a classe do sklearn proporciona é o método `predict_proba()`\n",
    "\n",
    "Esse método retorna exatamente qual é a **probabilidade modelada pelo logit**, isto é, $P(y=1 | \\vec{x})$.\n",
    "\n",
    "Isso pode ser muito útil, pois assim conseguimos **mudar qual é o cutoff de escolha de classe** para ser algo diferente de 0.5!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar diferentes cutoffs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T21:02:22.107468Z",
     "start_time": "2022-01-14T21:02:21.891032Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes:\n",
      " [[-0.056  0.266 -0.    -0.027  0.002]]\n",
      "\n",
      "Intercept: [0.005]\n",
      "\n",
      "Classes: [0 1]\n",
      "\n",
      "###################################################\n",
      "\n",
      "Avaliação de modelos com diferentes valores de cutoff\n",
      "\n",
      "###################################################\n",
      "\n",
      "\n",
      " Cutoff: 0.2\n",
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "[[127  19]\n",
      " [ 13 141]]\n",
      "\n",
      "Classification report do modelo nos dados de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       146\n",
      "           1       0.88      0.92      0.90       154\n",
      "\n",
      "    accuracy                           0.89       300\n",
      "   macro avg       0.89      0.89      0.89       300\n",
      "weighted avg       0.89      0.89      0.89       300\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n",
      "\n",
      " Cutoff: 0.3\n",
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "[[133  13]\n",
      " [ 17 137]]\n",
      "\n",
      "Classification report do modelo nos dados de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       146\n",
      "           1       0.91      0.89      0.90       154\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.90      0.90      0.90       300\n",
      "weighted avg       0.90      0.90      0.90       300\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n",
      "\n",
      " Cutoff: 0.4\n",
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "[[136  10]\n",
      " [ 23 131]]\n",
      "\n",
      "Classification report do modelo nos dados de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       146\n",
      "           1       0.93      0.85      0.89       154\n",
      "\n",
      "    accuracy                           0.89       300\n",
      "   macro avg       0.89      0.89      0.89       300\n",
      "weighted avg       0.89      0.89      0.89       300\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n",
      "\n",
      " Cutoff: 0.5\n",
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "[[140   6]\n",
      " [ 25 129]]\n",
      "\n",
      "Classification report do modelo nos dados de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       146\n",
      "           1       0.96      0.84      0.89       154\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.90      0.90      0.90       300\n",
      "weighted avg       0.90      0.90      0.90       300\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n",
      "\n",
      " Cutoff: 0.6\n",
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "[[141   5]\n",
      " [ 34 120]]\n",
      "\n",
      "Classification report do modelo nos dados de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.97      0.88       146\n",
      "           1       0.96      0.78      0.86       154\n",
      "\n",
      "    accuracy                           0.87       300\n",
      "   macro avg       0.88      0.87      0.87       300\n",
      "weighted avg       0.88      0.87      0.87       300\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n",
      "\n",
      " Cutoff: 0.7\n",
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "[[144   2]\n",
      " [ 38 116]]\n",
      "\n",
      "Classification report do modelo nos dados de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88       146\n",
      "           1       0.98      0.75      0.85       154\n",
      "\n",
      "    accuracy                           0.87       300\n",
      "   macro avg       0.89      0.87      0.87       300\n",
      "weighted avg       0.89      0.87      0.87       300\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n",
      "\n",
      " Cutoff: 0.8\n",
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "[[144   2]\n",
      " [ 42 112]]\n",
      "\n",
      "Classification report do modelo nos dados de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87       146\n",
      "           1       0.98      0.73      0.84       154\n",
      "\n",
      "    accuracy                           0.85       300\n",
      "   macro avg       0.88      0.86      0.85       300\n",
      "weighted avg       0.88      0.85      0.85       300\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n",
      "\n",
      " Cutoff: 0.9\n",
      "\n",
      "Matriz de confusão do modelo nos dados de teste:\n",
      "[[145   1]\n",
      " [ 57  97]]\n",
      "\n",
      "Classification report do modelo nos dados de teste:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.99      0.83       146\n",
      "           1       0.99      0.63      0.77       154\n",
      "\n",
      "    accuracy                           0.81       300\n",
      "   macro avg       0.85      0.81      0.80       300\n",
      "weighted avg       0.86      0.81      0.80       300\n",
      "\n",
      "\n",
      "##########################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# leia a base\n",
    "df = pd.read_csv(\"../datasets/advertising.csv\")\n",
    "\n",
    "# apenas as features numericas\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# separe as features e o target\n",
    "X = df.drop(columns = 'Clicked on Ad')\n",
    "y = df['Clicked on Ad']\n",
    "\n",
    "# 1) importe a classe do classificador\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 2) instancie a classe\n",
    "estimador = LogisticRegression()\n",
    "\n",
    "# 3) faça o train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "# 4) treine o modelo\n",
    "modelo = estimador.fit(X_train, y_train)\n",
    "\n",
    "# dê uma olhada nos coeficientes\n",
    "print(\"Coeficientes:\\n\", modelo.coef_)\n",
    "print(\"\\nIntercept:\", modelo.intercept_)\n",
    "\n",
    "# dê uma olhada nas classes do modelo\n",
    "classes =  modelo.classes_\n",
    "print(\"\\nClasses:\", classes)\n",
    "\n",
    "# 5) probabilidades das previsões\n",
    "probs = modelo.predict_proba(X_test)\n",
    "\n",
    "# probabilidade de pertencimento à classe 1\n",
    "probs_1 = probs[:, 1]\n",
    "\n",
    "# avaliação  do modelo\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "threshold_list = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "print(\"\\n###################################################\\n\")\n",
    "print(\"Avaliação de modelos com diferentes valores de cutoff\")\n",
    "print(\"\\n###################################################\\n\")\n",
    "\n",
    "for threshold in threshold_list:\n",
    "    \n",
    "    print(\"\\n Cutoff:\", threshold)\n",
    "    \n",
    "    # previsões\n",
    "    y_pred = np.where(probs_1 > threshold, 1, 0)\n",
    "\n",
    "    print(\"\\nMatriz de confusão do modelo nos dados de teste:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(\"\\nClassification report do modelo nos dados de teste:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(\"\\n##########################################################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "### Tradeoff precision/recall\n",
    "\n",
    "Conforme é possível ver acima, claramente há um **tradeoff** entre precision e recall conforme variamos o cutoff. Isso faz total sentido, dado que estas métricas representam!\n",
    "\n",
    "Podemos visualizar este tradeoff facilmente com o sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para plotar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou, então:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "\n",
    "### Curva ROC e AUC-ROC (AUROC)\n",
    "\n",
    "Veremos agora uma outra métrica de avaliação de modelos de classificação que é intimamente ligada com os diferentes thresholds possíveis -- a **AUC (Area Under The Curve) da curva ROC (Receiver Operating Characteristics)**, por vezes chamada de **AUROC (Area Under the Receiver Operating Characteristics)**\n",
    "\n",
    "A curva **ROC é uma curva de probabilidade**, sendo que **AUC é a área sob a curva**, representando **o grau de separabilidade atingido pelo modelo**.\n",
    "\n",
    "Ou seja, esta medida nos diz **o quanto o modelo é capaz de distinguir entre duas classes**.\n",
    "\n",
    "A curva ROC é construída com a **taxa de falsos positivos** no eixo x, e a **taxa de verdadeiros positivos** no eixo y, para diferentes **thresholds de classificação**:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1175/1*2nd7NTEBosPakccmLVWy9A.png\" width=500>\n",
    "\n",
    "O valor do AUC-ROC sempre estará **entre 0 e 1**, sendo que **quanto mais próximo de 1, melhor o modelo**.\n",
    "\n",
    "> Valores de AUC-ROC maiores que 0.5 (mais próximos de 1) significam que o modelo tem uma **taxa de veridadeiros positivos maior que a taxa de falsos positivos**, ou seja, o modelo está acertando mais!\n",
    "\n",
    "Quanto **mais próximo de 0** (para valores abaixo de 0.5), teremos um modelo que faz um bom trabalho em separar as classes, mas as classifica erroneamente.\n",
    "\n",
    "E, quanto **mas próximo de 0.5**, pior é o modelo em separar as classes: seria um modelo que simplesmente chuta aleatoriamente ora a classe 0, ora a classe 1. Veja as imagens a seguir para uma ilustração:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/528/1*Uu-t4pOotRQFoyrfqEvIEg.png\" width=500>\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/507/1*yF8hvKR9eNfqqej2JnVKzg.png\" width=500>\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/430/1*iLW_BrJZRI0UZSflfMrmZQ.png\" width=500>\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/556/1*aUZ7H-Lw74KSucoLlj1pgw.png\" width=500>\n",
    "\n",
    "Ao olhar para a curva em si, temos a seguinte interpretação:\n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/J9l8J1MeCbY/hqdefault.jpg\" width=400>\n",
    "\n",
    "Para aprender mais sobre a construção da curva ROC, sugiro [este StatQuest!](https://www.youtube.com/watch?v=4jRBRDbJemM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para plotar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, pra calcular o AUC-ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E se tivermos uma classificação multiclasse?\n",
    "\n",
    "Há problemas em que temos um problema de **classificação multiclasse**, pois há mais do que duas classes a serem preditas.\n",
    "\n",
    "<img src=\"https://utkuufuk.com/2018/06/03/one-vs-all-classification/one-vs-all.png\">\n",
    "\n",
    "Boa noitícia: o operacional de construção e avaliação do modelo com o sklearn muda em absolutamente **nada**.\n",
    "\n",
    "No entanto, conceitualmente, há algumas mudanças: a rigor, o modelo passa a se chamar **regresão logística MULTINOMIAL**, cujo processo de classificação é dado pela função **softmax**:\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/YLeRi.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para quem quiser saber mais sobre o \"logit score\", [clique aqui](https://stats.stackexchange.com/questions/329857/what-is-the-difference-between-decision-function-predict-proba-and-predict-fun).\n",
    "\n",
    "Essencialmente, esse é o valor do termo linear usado como argumento da sigmoide, isto é, $z(x) = b_0 + b_1 x_1 + \\cdots + b_p x_p$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "249.667px",
    "width": "359.667px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
